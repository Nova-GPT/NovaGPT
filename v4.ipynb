{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35f5660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "# os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d4715b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "# !pip3 install bitsandbytes transformers livelossplot matplotlib tqdm scikit-learn\n",
    "# !pip3 install mixture-of-experts pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "068d1757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/mnt/c/Users/Arush Bansal/OneDrive - IIT Delhi/Desktop/arushGPT')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1e2775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1833966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e371554a70>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from layers.RegexTokenizer import RegexTokenizer\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.amp import autocast, GradScaler\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "import time\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "from livelossplot import PlotLosses\n",
    "\n",
    "from utils import ModelSpecs, TrainingData\n",
    "from layers.Block import Block\n",
    "# from layers.MLA_Block import Block\n",
    "# from layers.WGQA_Block import Block\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5830e9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.1+cu118'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de50a3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-3.5-mini-instruct\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
    "stories = TrainingData.TinyStories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9195fa0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Cuda device.\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "modelSpecs = ModelSpecs.create('mid', VOCAB_SIZE=tokenizer.vocab_size)\n",
    "# BATCH_SIZE = 38 # how many independent sequences will we process in parallel?\n",
    "# BATCH_SIZE = 28 # how many independent sequences will we process in parallel?\n",
    "BATCH_SIZE = 2 # how many independent sequences will we process in parallel?\n",
    "MAX_ITERS = 2000\n",
    "LEARNING_RATE = 3e-4\n",
    "EVAL_INTERVALS = 100\n",
    "# EVAL_ITERS = 200\n",
    "EVAL_ITERS = 50\n",
    "TRAIN_TEST_SPLIT = 0.9\n",
    "# device = 'cpu'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Running on {device.capitalize()} device.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09b4badb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.730612 M\n"
     ]
    }
   ],
   "source": [
    "i = 8\n",
    "text = stories[int(10**6 * 0.730612 * i):int(10**6 * 0.730612 *(i+1) )]\n",
    "# text = TrainingData.TinyStories()[:int(10**6 * 0.730612 * 20 * 5)]\n",
    "print(len(text)/10**6,\"M\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ba71be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (184703 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.184703 M\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = torch.tensor(tokenizer.encode(text))\n",
    "\n",
    "n = int(TRAIN_TEST_SPLIT * len(data))\n",
    "print(len(data)/10**6,\"M\")\n",
    "\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "209488c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - modelSpecs.BLOCK_SIZE, (BATCH_SIZE,))\n",
    "    x = torch.stack([data[i:i+modelSpecs.BLOCK_SIZE] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+modelSpecs.BLOCK_SIZE+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b45497b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(modelSpecs.VOCAB_SIZE, modelSpecs.N_EMBD)\n",
    "        self.position_embedding_table = nn.Embedding(modelSpecs.BLOCK_SIZE, modelSpecs.N_EMBD)\n",
    "        self.blocks = nn.Sequential(*[Block(modelSpecs) for _ in range(modelSpecs.N_LAYER)])\n",
    "        self.ln_f = nn.LayerNorm(modelSpecs.N_EMBD) # final layer norm\n",
    "        self.lm_head = nn.Linear(modelSpecs.N_EMBD, modelSpecs.VOCAB_SIZE)\n",
    "\n",
    "        # better init, not covered in the original GPT video, but important, will cover in followup video\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -modelSpecs.BLOCK_SIZE:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b945baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss(model : GPTLanguageModel):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(EVAL_ITERS)\n",
    "        for k in range(EVAL_ITERS):\n",
    "            X, Y = get_batch(split)\n",
    "            with autocast(device_type='cuda', dtype=torch.float16):\n",
    "                _, loss = model(X, Y)\n",
    "            # _, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee2d519e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.386577 M parameters\n"
     ]
    }
   ],
   "source": [
    "m = GPTLanguageModel()\n",
    "m = m.to(device)\n",
    "# m = torch.compile(m, mode='default') # TODO use this when ready to use linux, and ready to train a 100M model\n",
    "# m = torch.compile(m, backend='aot_eager')\n",
    "# m = torch.compile(m, mode='reduce-overhead', backend='inductor') \n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
    "\n",
    "# create a PyTorch optimizer\n",
    "# optimizer = torch.optim.AdamW(m.parameters(), lr=LEARNING_RATE)\n",
    "optimizer = bnb.optim.AdamW8bit(m.parameters(), lr=LEARNING_RATE)\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54a0847f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# startTime = time.time()\n",
    "# m.train()\n",
    "\n",
    "# # torch.backends.cudnn.benchmark = True\n",
    "# # torch.backends.cuda.matmul.allow_tf32 = True\n",
    "# # torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "# # temporary line\n",
    "# MAX_ITERS = 800 // BATCH_SIZE\n",
    "# torch.cuda.empty_cache()\n",
    "# iter99Str = \"\"\n",
    "# iter99time = None\n",
    "# ACCUMILATION = 2\n",
    "# for iter in range(0, MAX_ITERS, ACCUMILATION):\n",
    "#     print(f\"iter #{iter}\")\n",
    "#     is_target_iter = (iter == ACCUMILATION)\n",
    "#     # torch.cuda.empty_cache()\n",
    "    \n",
    "#     # every once in a while evaluate the loss on train and val sets\n",
    "#     # if iter % EVAL_INTERVALS == 0 or iter == MAX_ITERS - 1:\n",
    "#     #     losses = estimate_loss(model)\n",
    "#         # print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}, time {(time.time() - startTime)/60:.2f} minutes\")\n",
    "#         # print (f\"step {iter}:  time {(time.time() - startTime)/60:.2f} minutes\")\n",
    "    \n",
    "#     # torch.cuda.empty_cache()\n",
    "#     # sample a batch of data\n",
    "#     if is_target_iter : iter99time = time.time()\n",
    "\n",
    "#     # evaluate the loss\n",
    "#     optimizer.zero_grad(set_to_none=True)    \n",
    "\n",
    "#     for i in range(ACCUMILATION):\n",
    "#         # torch.compiler.cudagraph_mark_step_begin()\n",
    "#         with autocast(device_type='cuda', dtype=torch.float16):\n",
    "#             xb, yb = get_batch('train') \n",
    "#             logits, loss = m(xb, yb)\n",
    "#         scaler.scale(loss/ ACCUMILATION).backward()\n",
    "\n",
    "#     if is_target_iter :\n",
    "#         print(f\"forwardbackwardPass {time.time() - iter99time:.1f}s \", end=\"\")\n",
    "#         iter99time = time.time()\n",
    "#     scaler.step(optimizer)\n",
    "#     if is_target_iter :\n",
    "#         print(f\"backwardPassStep {time.time() - iter99time:.1f}s \", end=\"\")\n",
    "#         iter99time = time.time()\n",
    "\n",
    "#     scaler.update()\n",
    "\n",
    "#     if is_target_iter :\n",
    "#         print(f\"backwardPassUpdate {time.time() - iter99time:.1f}s\")\n",
    "#         iter99time = time.time()\n",
    "\n",
    "\n",
    "# print(f\"{torch.cuda.memory_allocated() / 1e6:.1f}MB {torch.cuda.max_memory_allocated() / 1e6:.1f}MB(peak) allocated, {torch.cuda.memory_reserved() / 1e6:.1f}MB reserved\")\n",
    "\n",
    "\n",
    "# endTime = time.time()\n",
    "# print(f\"Total Training Time : {(endTime - startTime)/60:.2f} minutes\")\n",
    "\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cba1d889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import torch\n",
    "# # from torch.cuda.amp import autocast, GradScaler\n",
    "# # from livelossplot import PlotLosses\n",
    "# # import time\n",
    "\n",
    "# # ---------------------- CONFIG ----------------------\n",
    "# ITERS = 100\n",
    "# ACCUMULATION_STEPS = 2\n",
    "# EVAL_INTERVALS = 20\n",
    "# TRAIN_TEST_SPLIT = 0.9\n",
    "# liveloss = PlotLosses()\n",
    "# scaler = GradScaler()\n",
    "\n",
    "# # ---------------------- TRAINING ----------------------\n",
    "# startTime = time.time()\n",
    "# step = BATCH_SIZE * modelSpecs.BLOCK_SIZE * ITERS * 8\n",
    "\n",
    "# for story_start in range(989_593_600, len(stories), step):\n",
    "#     print(f\"\\n=== OUTER ITER: {story_start // step} | STRING INDEX: {story_start} ===\")\n",
    "#     text = stories[story_start : story_start + step]\n",
    "#     data = torch.tensor(tokenizer.encode(text), dtype=torch.long)\n",
    "#     n = int(TRAIN_TEST_SPLIT * len(data))\n",
    "#     print(f\"Tokens: {len(data)/1e6:.2f}M\")\n",
    "\n",
    "#     train_data, val_data = data[:n], data[n:]\n",
    "#     del data\n",
    "#     torch.cuda.empty_cache()\n",
    "\n",
    "#     m.train()\n",
    "#     MAX_ITERS = ITERS // ACCUMULATION_STEPS\n",
    "\n",
    "#     for iter in range(MAX_ITERS):\n",
    "#         iter_start = time.time()\n",
    "#         is_profile_iter = (iter == ACCUMULATION_STEPS)  # for timing breakdown\n",
    "        \n",
    "#         optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "#         # ---------------------- ACCUMULATED GRADIENTS ----------------------\n",
    "#         for acc_step in range(ACCUMULATION_STEPS):\n",
    "#             with autocast(device_type='cuda', dtype=torch.float16):\n",
    "#                 xb, yb = get_batch('train')\n",
    "#                 logits, loss = m(xb, yb)\n",
    "#                 scaled_loss = loss / ACCUMULATION_STEPS\n",
    "#             scaler.scale(scaled_loss).backward()\n",
    "\n",
    "#         # ---------------------- OPTIMIZER STEP ----------------------\n",
    "#         if is_profile_iter: t1 = time.time()\n",
    "#         scaler.step(optimizer)\n",
    "#         if is_profile_iter: \n",
    "#             print(f\"Forward+Backward: {t1 - iter_start:.1f}s\", end=\" \")\n",
    "#             t2 = time.time()\n",
    "#         scaler.update()\n",
    "#         if is_profile_iter:\n",
    "#             print(f\"Step: {t2 - t1:.1f}s Update: {time.time() - t2:.1f}s\")\n",
    "\n",
    "#         # ---------------------- EVAL + LOGGING ----------------------\n",
    "#         if iter % EVAL_INTERVALS == 0 or iter == MAX_ITERS - 1:\n",
    "#             torch.cuda.empty_cache()\n",
    "#             losses = estimate_loss(m)\n",
    "#             liveloss.update({'loss': losses['train'], 'val_loss': losses['val']})\n",
    "#             liveloss.send()\n",
    "#             elapsed = int((time.time() - startTime)//60)\n",
    "#             print(f\"\\n[Eval] Iter {iter}/{MAX_ITERS} | Train: {losses['train']:.4f} | Val: {losses['val']:.4f} | Time: {elapsed} min\")\n",
    "#             torch.cuda.empty_cache()\n",
    "\n",
    "#     print(f\"Outer Loop {story_start // step} done. Total Time: {(time.time() - startTime)/60:.2f} min\\n\")\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "# print(f\"Training Completed in {(time.time() - startTime)/60:.2f} minutes.\")\n",
    "# print(f\"Memory: {torch.cuda.memory_allocated()/1e6:.1f}MB used, {torch.cuda.max_memory_allocated()/1e6:.1f}MB peak, {torch.cuda.memory_reserved()/1e6:.1f}MB reserved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362985cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss\n",
      "\ttraining         \t (min:    5.523, max:   10.241, cur:    5.523)\n",
      "\tvalidation       \t (min:    5.466, max:   10.259, cur:    5.466)\n",
      "[Eval] Iter 0/2000 | Train: 5.5230 | Val: 5.4663 | Time: 127.0 min\n",
      "Training Progress:   0%|                             | 1/581 [01:16<8:54:06, 55.25s/it, slice=2/581]"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# from torch.cuda.amp import autocast, GradScaler\n",
    "# from livelossplot import PlotLosses\n",
    "from tqdm import tqdm\n",
    "# import time\n",
    "import sys\n",
    "\n",
    "# ---------------------- CONFIG ----------------------\n",
    "ITERS = 100\n",
    "ACCUMULATION_STEPS = 2\n",
    "EVAL_INTERVALS = 100\n",
    "TRAIN_TEST_SPLIT = 0.9\n",
    "liveloss = PlotLosses()\n",
    "scaler = GradScaler()\n",
    "\n",
    "# ---------------------- TRAINING ----------------------\n",
    "startTime = time.time()\n",
    "step = BATCH_SIZE * modelSpecs.BLOCK_SIZE * ITERS * 8\n",
    "outer_starts = list(range(0, len(stories), step))\n",
    "num_outer_loops = len(outer_starts)\n",
    "\n",
    "# tqdm progress bar for dataset coverage\n",
    "pbar = tqdm(total=num_outer_loops, desc=\"Training Progress\", ncols=100, file=sys.stdout)\n",
    "\n",
    "for outer_idx, story_start in enumerate(outer_starts):\n",
    "    pbar.set_postfix({\"slice\": f\"{outer_idx+1}/{num_outer_loops}\"})\n",
    "\n",
    "    # Move tqdm bar before printing any normal logs\n",
    "    pbar.refresh()\n",
    "    print(f\"\\n=== OUTER ITER: {outer_idx+1}/{num_outer_loops} | STRING INDEX: {story_start} ===\")\n",
    "\n",
    "    text = stories[story_start : story_start + step]\n",
    "    data = torch.tensor(tokenizer.encode(text), dtype=torch.long)\n",
    "    n = int(TRAIN_TEST_SPLIT * len(data))\n",
    "    print(f\"Tokens: {len(data)/1e6:.2f}M\")\n",
    "\n",
    "    train_data, val_data = data[:n], data[n:]\n",
    "    del data\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    m.train()\n",
    "\n",
    "    for iter in range(0, ITERS, ACCUMULATION_STEPS):\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # ----------- ACCUMULATED GRADIENTS -----------\n",
    "        for _ in range(ACCUMULATION_STEPS):\n",
    "            with autocast(device_type='cuda', dtype=torch.float16):\n",
    "                xb, yb = get_batch('train')\n",
    "                logits, loss = m(xb, yb)\n",
    "                scaler.scale(loss / ACCUMULATION_STEPS).backward()\n",
    "\n",
    "        # ----------- OPTIMIZER STEP -----------\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        # ----------- PERIODIC EVAL + LOGGING -----------\n",
    "        if iter % EVAL_INTERVALS == 0 or iter == MAX_ITERS - 1:\n",
    "            # torch.cuda.empty_cache()\n",
    "            losses = estimate_loss(m)\n",
    "            liveloss.update({'loss': losses['train'], 'val_loss': losses['val']})\n",
    "            liveloss.send()\n",
    "            elapsed = (time.time() - startTime)/60//0.01\n",
    "            print(f\"[Eval] Iter {iter}/{MAX_ITERS} | Train: {losses['train']:.4f} | Val: {losses['val']:.4f} | Time: {elapsed} min\")\n",
    "            pbar.refresh()\n",
    "\n",
    "    pbar.update(1)\n",
    "    pbar.refresh()  # ensures the bar stays visible\n",
    "    outer_elapsed = (time.time() - startTime)/60\n",
    "\n",
    "pbar.close()\n",
    "torch.cuda.empty_cache()\n",
    "total_time = (time.time() - startTime)/60\n",
    "\n",
    "print(f\"\\n Training Completed in {total_time:.2f} minutes.\")\n",
    "print(f\"Memory: {torch.cuda.memory_allocated()/1e6:.1f}MB used, \"\n",
    "      f\"{torch.cuda.max_memory_allocated()/1e6:.1f}MB peak, \"\n",
    "      f\"{torch.cuda.memory_reserved()/1e6:.1f}MB reserved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7d7374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ITERS = 100\n",
    "# startTime = time.time()\n",
    "# step = BATCH_SIZE * modelSpecs.BLOCK_SIZE * ITERS * 8\n",
    "# liveloss = PlotLosses()\n",
    "\n",
    "# MAX_ITERS = 800 // BATCH_SIZE\n",
    "# ACCUMILATION = 2\n",
    "\n",
    "# # for i in range(step * 0, len(stories), step):\n",
    "# for i in range(0, len(stories), step):\n",
    "#     torch.cuda.empty_cache()\n",
    "#     print(\"ITER:\", i // step, \"::::\", \" STRING INDEX:\", i)\n",
    "#     text = stories[i : i + step]\n",
    "#     data = torch.tensor(tokenizer.encode(text))\n",
    "#     n = int(TRAIN_TEST_SPLIT * len(data))\n",
    "#     print(\"tokens\", len(data)/10**6,\"M\")\n",
    "#     train_data = data[:n]\n",
    "#     val_data = data[n:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     for iter in range(ITERS):\n",
    "#         print(f\"iter #{iter}\")\n",
    "        \n",
    "#         # every once in a while evaluate the loss on train and val sets\n",
    "#         if iter % EVAL_INTERVALS == 0 or iter == ITERS - 1:\n",
    "#             losses = estimate_loss(m)\n",
    "#             liveloss.update({ 'loss': losses['train'], 'val_loss': losses['val']})\n",
    "#             liveloss.send()\n",
    "#             print(\"ITER:\", i // step, \"::::\", \" STRING INDEX:\", i)\n",
    "#             print(\"tokens\", len(data)/10**6,\"M\")\n",
    "#             print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}, time {int((time.time() - startTime)//60)} minutes\")\n",
    "\n",
    "#         # sample a batch of data\n",
    "#         xb, yb = get_batch('train')\n",
    "\n",
    "#         # evaluate the loss\n",
    "#         logits, loss = m(xb, yb)\n",
    "#         optimizer.zero_grad(set_to_none=True)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#     endTime = time.time()\n",
    "#     print(f\"Total Training Time : {int((endTime - startTime)//60)} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9024eebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100M BATCH 8 BLOCK 512 16.77min 56.86days-for-2B-tokens\n",
    "# 100M BATCH 8 BLOCK 512 11.82min 40.07days-for-2B-tokens 1654MB 7756MB (peak) allocated 8512MB reserved\n",
    "\n",
    "# 22.2s\n",
    "#10.2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e628cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.backends.cuda.flash_sdp_enabled())       # should be True\n",
    "print(torch.backends.cuda.mem_efficient_sdp_enabled()) # True\n",
    "print(torch.backends.cuda.math_sdp_enabled())          # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb9ccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WGQA-8 16 head 16 layer - perplexity implimentation (95M param)\n",
    "# 1412.382208 MB allocated\n",
    "# 8919.369216 MB peak allocated\n",
    "# 9753.853952 MB reserved\n",
    "# Total Training Time : 12.06 minutes\n",
    "\n",
    "# WGQA-8 16 head 18 layer - perplexity implimentation (95M param)\n",
    "# 1412.382208 MB allocated\n",
    "# 8919.369216 MB peak allocated\n",
    "# 9753.853952 MB reserved\n",
    "# Total Training Time : 12.06 minutes\n",
    "\n",
    "# WGQA-8 16 head 18 layer - perplexity implimentation (103M param)\n",
    "# 1470.321152 MB allocated\n",
    "# 10227.390976 MB peak allocated\n",
    "# 10525.605888 MB reserved\n",
    "# Total Training Time : 15.58 minutes\n",
    "\n",
    "# MLA 16 head 8 layer - 103M param (76M param)\n",
    "# 1696.742912 MB allocated\n",
    "# 6963.769856 MB peak allocated\n",
    "# 7746.879488 MB reserved\n",
    "# Total Training Time : 4.31 minutes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b6ad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MHA 516Embed 12Heads 16Layers :aot_eager \n",
    "# 1702.7MB 7804.9MB(peak) allocated 8638.1MB reserved\n",
    "# Total Training Time : 13.01 minutes\n",
    "\n",
    "# MHA 516Embed 12Heads 16Layers :default \n",
    "# 1695.1MB 5558.3MB(peak) allocated, 5893.0MB reserved\n",
    "# Total Training Time : 16.79 minutes\n",
    "\n",
    "# MHA 516Embed 12Heads 16Layers :reduce-overhead:inductor \n",
    "# forwardPass 0.0s backwardPassScale 0.0s backwardPassStep 6.2s backwardPassUpdate 0.0s\n",
    "# 832.5MB 5885.0MB(peak) allocated, 6341.8MB reserved\n",
    "# Total Training Time : 15.12 minutes\n",
    "\n",
    "# MHA 516Embed 12Heads 16Layers :gradient-accumilation\n",
    "# BATCH 16 ITER 100 ACCUMILATION 1 : ~16min\n",
    "# BATCH 16 ITER 100 ACCUMILATION 2 : OOM Error\n",
    "# BATCH 08 ITER 200 ACCUMILATION 2 : 6.54min 1423.5MB 5743.7MB(peak) allocated, 6157.2MB reserved\n",
    "# BATCH 08 ITER 200 ACCUMILATION 4 : 6.89min 1423.5MB 5743.7MB(peak) allocated, 6157.2MB reserved\n",
    "# BATCH 08 ITER 200 ACCUMILATION 8 : ~7min forwardbackwardPass 16.8s backwardPassStep 0.3s backwardPassUpdate 0.0s\n",
    "\n",
    "# iter #99\n",
    "# 802.5MB 5817.1MB(peak) allocated, 6178.2MB reserved\n",
    "# Total Training Time : 9.90 minutes\n",
    "\n",
    "# MHA 512Embed 12Heads 16Layers :gradient-accumilation :\n",
    "# no-sqda 5.27min forwardbackwardPass 2.8s backwardPassStep 0.1s backwardPassUpdate 0.0s 1448.4MB 4803.8MB(peak) allocated, 5207.2MB reserved\n",
    "# sqda 6.19 minutes 1448.4MB 4845.2MB(peak) allocated, 5677.0MB reserved] \n",
    "\n",
    "# 1345.5MB 3120.2MB(peak) allocated, 3741.3MB reserved\n",
    "# Total Training Time : 6.47 minutes\n",
    "\n",
    "# Batch size 2 accumilation 2 mla block size 512 embed 516\n",
    "# 1306.3MB 3028.1MB(peak) allocated, 3231.7MB reserved\n",
    "# Total Training Time : 1.24 minutes\n",
    "\n",
    "\n",
    "# MLA batch 4 accumilation 2 mla block size 512 embed 516\n",
    "# forwardbackwardPass 2.0s backwardPassStep 0.1s backwardPassUpdate 0.0s\n",
    "# BATCH_SIZE = 4\n",
    "\n",
    "# MLA batch 2 accumlation mla block size 512 embed 516\n",
    "# forwardbackwardPass 0.7s backwardPassStep 0.1s backwardPassUpdate 0.0s\n",
    "# 1301.0MB 3025.9MB(peak) allocated, 3439.3MB reserved\n",
    "# Total Training Time : 1.12 minutes\n",
    "\n",
    "# MLA batch 1 accumlation 8 mla block size 512 embed 516\n",
    "# forwardbackwardPass 1.0s backwardPassStep 0.1s backwardPassUpdate 0.0s\n",
    "# 1159.5MB 2099.8MB(peak) allocated, 2300.6MB reserved\n",
    "# Total Training Time : 1.62 minutes\n",
    "\n",
    "# MLA batch 1 accumlation 4 mla block size 512 embed 516\n",
    "# forwardbackwardPass 0.5s backwardPassStep 0.1s backwardPassUpdate 0.0s\n",
    "# 1159.2MB 2094.4MB(peak) allocated, 2300.6MB reserved\n",
    "# Total Training Time : 1.69 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2434cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "who is the fastest!\" Anna says.\n",
      "\n",
      "They nod. They say, \" arc! winning is to vanish! One way is where you are and where you are going.\"\n",
      "\n",
      "The sun starts to dry. Anna and Ben are sad. They want to see the prettiest thing. They look for looks.\n",
      "\n",
      "They see\n"
     ]
    }
   ],
   "source": [
    "# input_tokens = torch.tensor(tokenizer.encode(\"there was once a forest with 100s of bushes\")).unsqueeze(0).cuda()\n",
    "input_tokens = torch.tensor(tokenizer.encode('who is the fastest')).unsqueeze(0).cuda()\n",
    "# print(input_tokens)\n",
    "\n",
    "m.eval()\n",
    "\n",
    "output_tokens = m.generate(input_tokens, max_new_tokens=64)[0]\n",
    "# print(output_tokens)\n",
    "\n",
    "m.train()\n",
    "\n",
    "output : str = tokenizer.decode(output_tokens)\n",
    "\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3aaf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1902\n"
     ]
    }
   ],
   "source": [
    "print(int(len(stories)//(10**6 )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b75341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ITERS = 100\n",
    "# startTime = time.time()\n",
    "# step = BATCH_SIZE * modelSpecs.BLOCK_SIZE * ITERS * 8\n",
    "# liveloss = PlotLosses()\n",
    "\n",
    "# # for i in range(step * 0, len(stories), step):\n",
    "# for i in range(989593600, len(stories), step):\n",
    "#     print(\"ITER:\", i // step, \"::::\", \" STRING INDEX:\", i)\n",
    "#     text = stories[i : i + step]\n",
    "#     data = torch.tensor(tokenizer.encode(text))\n",
    "#     n = int(TRAIN_TEST_SPLIT * len(data))\n",
    "#     print(\"tokens\", len(data)/10**6,\"M\")\n",
    "\n",
    "#     train_data = data[:n]\n",
    "#     val_data = data[n:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     for iter in range(ITERS):\n",
    "#         print(f\"iter #{iter}\")\n",
    "#         torch.cuda.empty_cache()\n",
    "#         # every once in a while evaluate the loss on train and val sets\n",
    "#         if iter % EVAL_INTERVALS == 0 or iter == ITERS - 1:\n",
    "#             losses = estimate_loss(m)\n",
    "#             liveloss.update({ 'loss': losses['train'], 'val_loss': losses['val']})\n",
    "#             liveloss.send()\n",
    "#             print(\"ITER:\", i // step, \"::::\", \" STRING INDEX:\", i)\n",
    "#             print(\"tokens\", len(data)/10**6,\"M\")\n",
    "#             print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}, time {int((time.time() - startTime)//60)} minutes\")\n",
    "            \n",
    "#         torch.cuda.empty_cache()\n",
    "#         # sample a batch of data\n",
    "#         xb, yb = get_batch('train')\n",
    "\n",
    "#         # evaluate the loss\n",
    "#         logits, loss = m(xb, yb)\n",
    "#         optimizer.zero_grad(set_to_none=True)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#     endTime = time.time()\n",
    "#     print(f\"Total Training Time : {int((endTime - startTime)//60)} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4da161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(989, 593, 600)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "655,360,000\n",
    "989,593,600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad3ef02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                     \n"
     ]
    }
   ],
   "source": [
    "input_tokens = torch.tensor(tokenizer.encode(\" \")).unsqueeze(0).cuda()\n",
    "# print(input_tokens)\n",
    "\n",
    "\n",
    "output_tokens = m.generate(input_tokens, max_new_tokens=100)[0]\n",
    "# print(output_tokens)\n",
    "\n",
    "output : str = tokenizer.decode(output_tokens)\n",
    "\n",
    "\n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10c6e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_optimizer_state_to_float32(optimizer : torch.optim.AdamW):\n",
    "    for state in optimizer.state.values():\n",
    "        for k, v in state.items():\n",
    "            if isinstance(v, torch.Tensor) and v.dtype == torch.float64:\n",
    "                state[k] = v.float()\n",
    "\n",
    "\n",
    "# Saving the model\n",
    "def save_model(model : nn.Module, optimizer : torch.optim.AdamW, filepath):\n",
    "    checkpoint = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(checkpoint, filepath)\n",
    "    print(f\"Model saved to {filepath}\")\n",
    "\n",
    "# Loading the model\n",
    "def load_model(model : nn.Module, optimizer : torch.optim.AdamW, filepath, device):\n",
    "    checkpoint = torch.load(filepath, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    convert_optimizer_state_to_float32(optimizer)\n",
    "\n",
    "    print(f\"Model loaded from {filepath}\")\n",
    "    model.to(device)\n",
    "    return model, optimizer\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a86e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save after training\n",
    "# save_model(m, optimizer, 'weights/gpt_model_50M.pth') # TODO improve this naming convention\n",
    "\n",
    "# # Later or for inference\n",
    "# # model = GPTLanguageModel()\n",
    "# # optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "# # model, optimizer = load_model(model, optimizer, 'gpt_model_checkpoint.pth', device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cdc81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_model = GPTLanguageModel()\n",
    "# pre_optimizer = torch.optim.AdamW(pre_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# loaded_model, loaded_optimizer = load_model(pre_model, pre_optimizer, './weights/gpt_model_50M.pth', device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a520c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model = loaded_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deab6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ITERS = 100\n",
    "# startTime = time.time()\n",
    "# step = BATCH_SIZE * modelSpecs.BLOCK_SIZE * ITERS * 8\n",
    "# liveloss = PlotLosses()\n",
    "\n",
    "# # for i in range(step * 0, len(stories), step):\n",
    "# for i in range(989593600, len(stories), step):\n",
    "#     print(\"ITER:\", i // step, \"::::\", \" STRING INDEX:\", i)\n",
    "#     text = stories[i : i + step]\n",
    "#     data = torch.tensor(tokenizer.encode(text))\n",
    "#     n = int(TRAIN_TEST_SPLIT * len(data))\n",
    "#     print(\"tokens\", len(data)/10**6,\"M\")\n",
    "\n",
    "#     train_data = data[:n]\n",
    "#     val_data = data[n:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     for iter in range(ITERS):\n",
    "#         print(f\"iter #{iter}\")\n",
    "#         torch.cuda.empty_cache()\n",
    "#         # every once in a while evaluate the loss on train and val sets\n",
    "#         if iter % EVAL_INTERVALS == 0 or iter == ITERS - 1:\n",
    "#             losses = estimate_loss(loaded_model)\n",
    "#             liveloss.update({ 'loss': losses['train'], 'val_loss': losses['val']})\n",
    "#             liveloss.send()\n",
    "#             print(\"ITER:\", i // step, \"::::\", \" STRING INDEX:\", i)\n",
    "#             print(\"tokens\", len(data)/10**6,\"M\")\n",
    "#             print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}, time {int((time.time() - startTime)//60)} minutes\")\n",
    "#         torch.cuda.empty_cache()\n",
    "#         # sample a batch of data\n",
    "#         xb, yb = get_batch('train')\n",
    "\n",
    "#         # evaluate the loss\n",
    "        \n",
    "#         logits, loss = loaded_model(xb, yb)\n",
    "#         loaded_optimizer.zero_grad(set_to_none=True)\n",
    "#         loss.backward()\n",
    "#         loaded_optimizer.step()\n",
    "\n",
    "#     endTime = time.time()\n",
    "#     print(f\"Total Training Time : {int((endTime - startTime)//60)} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbba3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_tokens = torch.tensor(tokenizer.encode(\" \")).unsqueeze(0).cuda()\n",
    "# # print(input_tokens)\n",
    "\n",
    "\n",
    "# output_tokens = loaded_model.generate(input_tokens, max_new_tokens=100)[0]\n",
    "# # print(output_tokens)\n",
    "\n",
    "# output : str = tokenizer.decode(output_tokens)\n",
    "\n",
    "\n",
    "\n",
    "# print(output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
